{
  "pipelineSpec": {
    "components": {
      "comp-classif-model-eval-metrics": {
        "executorLabel": "exec-classif-model-eval-metrics",
        "inputDefinitions": {
          "artifacts": {
            "model": {
              "artifactType": {
                "schemaTitle": "system.Model",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "api_endpoint": {
              "type": "STRING"
            },
            "location": {
              "type": "STRING"
            },
            "project": {
              "type": "STRING"
            },
            "thresholds_dict_str": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "metrics": {
              "artifactType": {
                "schemaTitle": "system.Metrics",
                "schemaVersion": "0.0.1"
              }
            },
            "metricsc": {
              "artifactType": {
                "schemaTitle": "system.ClassificationMetrics",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "dep_decision": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-condition-deploy-decision-1": {
        "dag": {
          "tasks": {
            "deploy": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-deploy"
              },
              "inputs": {
                "artifacts": {
                  "model": {
                    "componentInputArtifact": "pipelineparam--train-output_model"
                  }
                },
                "parameters": {
                  "endpoint": {
                    "componentInputParameter": "pipelineparam--endpoint"
                  },
                  "previous_model": {
                    "componentInputParameter": "pipelineparam--previous_model"
                  }
                }
              },
              "taskInfo": {
                "name": "deploy"
              }
            }
          }
        },
        "inputDefinitions": {
          "artifacts": {
            "pipelineparam--train-output_model": {
              "artifactType": {
                "schemaTitle": "system.Model",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "pipelineparam--classif-model-eval-metrics-dep_decision": {
              "type": "STRING"
            },
            "pipelineparam--endpoint": {
              "type": "STRING"
            },
            "pipelineparam--previous_model": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-deploy": {
        "executorLabel": "exec-deploy",
        "inputDefinitions": {
          "artifacts": {
            "model": {
              "artifactType": {
                "schemaTitle": "system.Model",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "endpoint": {
              "type": "STRING"
            },
            "previous_model": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "vertex_endpoint": {
              "artifactType": {
                "schemaTitle": "system.Artifact",
                "schemaVersion": "0.0.1"
              }
            },
            "vertex_model": {
              "artifactType": {
                "schemaTitle": "system.Model",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-train": {
        "executorLabel": "exec-train",
        "inputDefinitions": {
          "parameters": {
            "csv_path": {
              "type": "STRING"
            },
            "num_epochs": {
              "type": "INT"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "metrics": {
              "artifactType": {
                "schemaTitle": "system.Metrics",
                "schemaVersion": "0.0.1"
              }
            },
            "output_model": {
              "artifactType": {
                "schemaTitle": "system.Model",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      }
    },
    "deploymentSpec": {
      "executors": {
        "exec-classif-model-eval-metrics": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "classif_model_eval_metrics"
            ],
            "command": [
              "sh",
              "-c",
              "(python3 -m ensurepip || python3 -m ensurepip --user) && (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet                 --no-warn-script-location 'google-cloud-aiplatform' 'kfp==1.8.4' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet                 --no-warn-script-location 'google-cloud-aiplatform' 'kfp==1.8.4' --user) && \"$0\" \"$@\"",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef classif_model_eval_metrics(\n    project: str,\n    location: str,  # \"us-central1\",\n    api_endpoint: str,  # \"us-central1-aiplatform.googleapis.com\",\n    thresholds_dict_str: str,\n    model: Input[Model],\n    metrics: Output[Metrics],\n    metricsc: Output[ClassificationMetrics],\n) -> NamedTuple(\"Outputs\", [(\"dep_decision\", str)]):  # Return parameter.\n\n    \"\"\"This function renders evaluation metrics for an AutoML Tabular classification model.\n    It retrieves the classification model evaluation generated by the AutoML Tabular training\n    process, does some parsing, and uses that info to render the ROC curve and confusion matrix\n    for the model. It also uses given metrics threshold information and compares that to the\n    evaluation results to determine whether the model is sufficiently accurate to deploy.\n    \"\"\"\n    import json\n    import logging\n\n     # Use the given metrics threshold(s) to determine whether the model is \n    # accurate enough to deploy.\n    def classification_thresholds_check(metrics_dict, thresholds_dict):\n        ## TODO: LOGIC TO DEFINE IF MODEL WILL BE DEPLOYED 20%\n        logging.info(\"threshold checks passed.\")\n        return True\n\n    thresholds_dict = json.loads(thresholds_dict_str)\n    deploy = True #classification_thresholds_check(metrics_list[0], thresholds_dict)\n    if deploy:\n        dep_decision = \"true\"\n    else:\n        dep_decision = \"false\"\n    logging.info(\"deployment decision is %s\", dep_decision)\n\n    return (dep_decision,)\n\n"
            ],
            "image": "gcr.io/deeplearning-platform-release/tf2-cpu.2-3:latest"
          }
        },
        "exec-deploy": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "deploy"
            ],
            "command": [
              "sh",
              "-c",
              "(python3 -m ensurepip || python3 -m ensurepip --user) && (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet                 --no-warn-script-location 'google-cloud-aiplatform' 'kfp==1.8.4' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet                 --no-warn-script-location 'google-cloud-aiplatform' 'kfp==1.8.4' --user) && \"$0\" \"$@\"",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef deploy(\n    previous_model: str,\n    endpoint: str,\n    # Input model.\n    model: Input[Model],\n    vertex_endpoint: Output[Artifact],\n    vertex_model: Output[Model]\n    ):\n\n  import logging\n  logging.getLogger().setLevel(logging.INFO)\n\n  from google.cloud import aiplatform\n  aiplatform.init(project='windy-site-254307')\n\n  # Upload model\n  new_model = aiplatform.Model.upload(\n      display_name=f'churn-retraining',\n      artifact_uri=model.uri,\n      serving_container_image_uri='us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-3:latest'\n  )\n  logging.info('uploaded model: %s', new_model.resource_name)\n\n  # Deploy model\n  if endpoint:  # 80-20 split\n    deployed_endpoint = aiplatform.Endpoint(endpoint)\n    logging.info('deployed_endpoint: %s', endpoint)\n    logging.info('gca_resource: %s', deployed_endpoint.gca_resource)\n\n    # CAREFUL: model_id is not the same as deployed_model_id\n    deployed_model_id = deployed_endpoint.gca_resource.deployed_models[0].id\n    logging.info('deployed_model_id: %s', deployed_model_id)\n    endpoint_updated = new_model.deploy(\n        deployed_model_display_name=\"retraining-B\",\n        endpoint = deployed_endpoint,\n        machine_type='n1-standard-4',\n        traffic_split = {\"0\": 20, deployed_model_id: 80}\n    )\n  else: # first time, create endpoint with 100% split\n    endpoint_updated = new_model.deploy(\n        deployed_model_display_name=\"churn-model-A\",\n        machine_type='n1-standard-4'\n    )\n  logging.info('endpoint: %s', str(endpoint_updated))\n  vertex_endpoint.uri = endpoint_updated.resource_name\n  vertex_model.uri = endpoint_updated.resource_name\n\n"
            ],
            "image": "python:3.9"
          }
        },
        "exec-train": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "train"
            ],
            "command": [
              "sh",
              "-c",
              "(python3 -m ensurepip || python3 -m ensurepip --user) && (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet                 --no-warn-script-location 'pandas' 'google-cloud-aiplatform' 'fsspec' 'gcsfs' 'kfp==1.8.4' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet                 --no-warn-script-location 'pandas' 'google-cloud-aiplatform' 'fsspec' 'gcsfs' 'kfp==1.8.4' --user) && \"$0\" \"$@\"",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef train(\n    #dataset: Input[Dataset],\n\n    #dataset: InputArtifact(Dataset),\n    csv_path: str,\n    # Output artifact of type Model.\n    output_model: Output[Model],\n    metrics: Output[Metrics],\n    # An input parameter of type int with a default value.\n    num_epochs: int = 10,\n  ):        \n\n    import pandas as pd\n    import tensorflow as tf\n    import tensorflow.keras as keras\n    from google.cloud import aiplatform\n    import logging\n\n    logging.getLogger().setLevel(logging.INFO)\n\n    print(tf.__version__)\n\n\n    #Init Vertex AI experiment\n    aiplatform.init(project=\"windy-site-254307\")\n\n    sample_df = pd.read_csv(csv_path)\n\n    clean_sample_df = sample_df.dropna()\n    target = clean_sample_df['churned']\n    features = clean_sample_df.drop(['churned', 'timestamp'], axis=1)\n    numeric_features = features.select_dtypes(include=['int64'])\n    categorical_features = features.drop(['entity_type_customer', 'user_pseudo_id'], axis=1).select_dtypes(include=['object']).astype(str)\n\n    dataset = tf.data.Dataset.from_tensor_slices(({**dict(numeric_features), **dict(categorical_features)}, target))\n\n    train_ds = (dataset.skip(1000)\n                .batch(10, drop_remainder=True)\n                .cache()\n                .prefetch(tf.data.experimental.AUTOTUNE))\n    val_ds = (dataset.take(1000)\n            .batch(10, drop_remainder=True)\n            .cache()\n            .prefetch(tf.data.experimental.AUTOTUNE))\n\n    print(f'numeric features: {[cat for cat in numeric_features]}')\n    normalizers = {cat: keras.layers.experimental.preprocessing.Normalization() for cat in numeric_features}\n    for cat, normalizer in normalizers.items():\n        print(f'adapting {cat} numeric normalizer with {numeric_features[cat].values}')\n        normalizer.adapt(train_ds.map(lambda x, y: x[cat]))\n\n    print(f'categorical features: {[cat for cat in categorical_features]}')\n    str_lookups = {cat: keras.layers.experimental.preprocessing.StringLookup() for cat in categorical_features}\n    for cat, str_lookup in str_lookups.items():\n        print(f'adapting {cat} string lookup with {categorical_features[cat].values}')\n        str_lookup.adapt(train_ds.map(lambda x, y: x[cat]))\n\n    #Num tokens is amount of unique strings + out-of-value + mask tokens\n    print(f'num_tokens: {[len(categorical_features[cat].unique())+2 for cat in categorical_features]}')\n    str_encoders = {cat: keras.layers.experimental.preprocessing.CategoryEncoding(num_tokens=len(categorical_features[cat].unique())+2, output_mode=\"binary\") for cat in categorical_features}\n    for cat, str_encode in str_encoders.items():\n        print(f'adapting {cat} string encoder with {str_lookups[cat](categorical_features[cat].values)}')\n        str_encode.adapt(train_ds.map(lambda x, y: str_lookups[cat](x[cat])))\n\n    numeric_inputs = {cat: keras.Input(shape=(), name=cat) for cat in numeric_features}\n    categorical_inputs = {cat: keras.Input(shape=(), name=cat, dtype=tf.string) for cat in categorical_features}\n\n    numeric_normalized = [normalizers[cat](numeric_inputs[cat]) for cat in numeric_inputs]\n    categorical_normalized = [str_encoders[cat](str_lookups[cat](categorical_inputs[cat])) for cat in categorical_inputs]\n\n    concat_num = keras.layers.Concatenate()(numeric_normalized)\n    concat_cat = keras.layers.Concatenate()(categorical_normalized)\n    concat = keras.layers.Concatenate()([concat_num, concat_cat])\n\n    hidden1 = keras.layers.Dense(128, activation='relu')(concat)\n    hidden2 = keras.layers.Dense(64, activation='relu')(hidden1)\n    output = keras.layers.Dense(1, activation='sigmoid', name='churned')(hidden2)\n\n    tf_model = keras.Model(inputs={**numeric_inputs, **categorical_inputs}, outputs=output)\n    tf_model.summary()\n\n    tf_model.compile(optimizer='adam', \n                loss='binary_crossentropy',\n                metrics=['binary_accuracy', tf.keras.metrics.FalsePositives(), tf.keras.metrics.FalseNegatives()])\n\n    print('Training the model...')\n    history = tf_model.fit(train_ds, validation_data=val_ds, epochs=10)\n    print('Evaluating the model...')\n    evaluation = tf_model.evaluate(val_ds)\n\n    tf_model.summary()\n\n    tf_model.save(output_model.path)\n    logging.info('using model.uri: %s', output_model.uri)\n\n"
            ],
            "image": "gcr.io/deeplearning-platform-release/tf2-cpu.2-5:latest"
          }
        }
      }
    },
    "pipelineInfo": {
      "name": "retraining-demo-uscentral1"
    },
    "root": {
      "dag": {
        "outputs": {
          "artifacts": {
            "classif-model-eval-metrics-metrics": {
              "artifactSelectors": [
                {
                  "outputArtifactKey": "metrics",
                  "producerSubtask": "classif-model-eval-metrics"
                }
              ]
            },
            "classif-model-eval-metrics-metricsc": {
              "artifactSelectors": [
                {
                  "outputArtifactKey": "metricsc",
                  "producerSubtask": "classif-model-eval-metrics"
                }
              ]
            },
            "train-metrics": {
              "artifactSelectors": [
                {
                  "outputArtifactKey": "metrics",
                  "producerSubtask": "train"
                }
              ]
            }
          }
        },
        "tasks": {
          "classif-model-eval-metrics": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-classif-model-eval-metrics"
            },
            "dependentTasks": [
              "train"
            ],
            "inputs": {
              "artifacts": {
                "model": {
                  "taskOutputArtifact": {
                    "outputArtifactKey": "output_model",
                    "producerTask": "train"
                  }
                }
              },
              "parameters": {
                "api_endpoint": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "us-central1-aiplatform.googleapis.com"
                    }
                  }
                },
                "location": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "us-central1"
                    }
                  }
                },
                "project": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "windy-site-254307"
                    }
                  }
                },
                "thresholds_dict_str": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "{\"auRoc\": 0.95}"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "classif-model-eval-metrics"
            }
          },
          "condition-deploy-decision-1": {
            "componentRef": {
              "name": "comp-condition-deploy-decision-1"
            },
            "dependentTasks": [
              "classif-model-eval-metrics",
              "train"
            ],
            "inputs": {
              "artifacts": {
                "pipelineparam--train-output_model": {
                  "taskOutputArtifact": {
                    "outputArtifactKey": "output_model",
                    "producerTask": "train"
                  }
                }
              },
              "parameters": {
                "pipelineparam--classif-model-eval-metrics-dep_decision": {
                  "taskOutputParameter": {
                    "outputParameterKey": "dep_decision",
                    "producerTask": "classif-model-eval-metrics"
                  }
                },
                "pipelineparam--endpoint": {
                  "componentInputParameter": "endpoint"
                },
                "pipelineparam--previous_model": {
                  "componentInputParameter": "previous_model"
                }
              }
            },
            "taskInfo": {
              "name": "condition-deploy-decision-1"
            },
            "triggerPolicy": {
              "condition": "inputs.parameters['pipelineparam--classif-model-eval-metrics-dep_decision'].string_value == 'true'"
            }
          },
          "train": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-train"
            },
            "inputs": {
              "parameters": {
                "csv_path": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://vertex-model-governance-lab/000000000000.csv"
                    }
                  }
                },
                "num_epochs": {
                  "runtimeValue": {
                    "constantValue": {
                      "intValue": "5"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "train"
            }
          }
        }
      },
      "inputDefinitions": {
        "parameters": {
          "endpoint": {
            "type": "STRING"
          },
          "previous_model": {
            "type": "STRING"
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "classif-model-eval-metrics-metrics": {
            "artifactType": {
              "schemaTitle": "system.Metrics",
              "schemaVersion": "0.0.1"
            }
          },
          "classif-model-eval-metrics-metricsc": {
            "artifactType": {
              "schemaTitle": "system.ClassificationMetrics",
              "schemaVersion": "0.0.1"
            }
          },
          "train-metrics": {
            "artifactType": {
              "schemaTitle": "system.Metrics",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "schemaVersion": "2.0.0",
    "sdkVersion": "kfp-1.8.4"
  },
  "runtimeConfig": {}
}